from __future__ import annotations
import asyncio, time, json, textwrap, os, re
from typing import Dict, Any, List, Tuple
from pathlib import Path
from .sse import StreamHub
from .registry import available_models
from .db import get_engine, update_task_status
from .metrics import (
    router_route_count, compile_pass_total, test_smoke_pass_total,
    duel_selection_decisions_total, duel_rule_decisions_total
)
from sqlalchemy import text
from .llm.ollama_client import generate_stream, OllamaError
from .bandit import extract_features, feature_hash, upsert_stat, rank_models
from .duel_config import get_duel_config
from .exec_sandbox import run_sandboxed
from .build_java import build_and_test_java
from .logging_setup import get_logger
from .logctx import set_task_id, set_candidate
from .bandit_store import record_event as bandit_record_event
from .artifacts import write_result

log = get_logger("queue")

FENCE_RX = re.compile(r"^\s*```.*$")
PACKAGE_LINE_RX = re.compile(r"^\s*package\s+([a-zA-Z0-9_.]+)\s*;\s*$")

CANDIDATE_TIMEOUT_SEC = int(os.getenv("CANDIDATE_TIMEOUT_SEC", "60"))
DUEL_TIMEOUT_SEC = int(os.getenv("DUEL_TIMEOUT_SEC", "120"))

def _format_model_name(m: Dict[str, Any]) -> str:
    size = str(m.get("size","")).lower()
    size_tag = size if size.endswith("b") else (f"{size}b" if size else "")
    quant = m.get("quant","")
    return f"{m.get('name')}:{size_tag}-{quant}".strip("-")

def _derive_java_pkg_class(rel_path: str) -> Tuple[str, str]:
    parts = rel_path.strip("/").split("/")
    try:
        idx = parts.index("java")
        pkg_parts = parts[idx+1:-1]
        cls = os.path.splitext(parts[-1])[0]
        pkg = ".".join(pkg_parts) if pkg_parts else ""
        return pkg, cls
    except ValueError:
        pkg_parts = parts[:-1]
        cls = os.path.splitext(parts[-1])[0] if parts else "Main"
        pkg = ".".join(p for p in pkg_parts if p not in ("src","main"))
        return pkg, cls

def _build_prompt(job: dict) -> str:
    lang = job["input"]["language"]
    goal = job["input"].get("goal","Generate code.")
    frameworks = ", ".join(job["input"].get("frameworks", [])) or "none"
    expected_files = (job.get("output_contract") or {}).get("expected_files", [])
    files_str = "\n".join(f"- {p}" for p in expected_files) if expected_files else "- (decide suitable path)"
    pkg_hint, cls_hint = _derive_java_pkg_class(expected_files[0]) if (expected_files and expected_files[0].endswith(".java")) else ("", "")
    return textwrap.dedent(f"""
    You are a senior {lang} engineer. Task: {goal}
    Frameworks: {frameworks}
    Output requirements (first file is primary target):
    {files_str}
    Package: {pkg_hint if pkg_hint else "(decide reasonable)"}
    ClassName: {cls_hint if cls_hint else "(decide reasonable)"}

    CRITICAL:
    - Return ONLY the file contents (no backticks, no prose).
    - For Java: include a correct package line and a compilable type.
    - Prefer plain JDK APIs (no third-party).
    """).strip()

def _sanitize_java(code: str, rel_path: str) -> str:
    lines = code.splitlines()
    cleaned: List[str] = []
    for ln in lines:
        if FENCE_RX.match(ln): continue
        if ln.strip().startswith(("http://","https://")): continue
        if ln.strip().lower().startswith(("for more information","status ","error ","warning ")): continue
        cleaned.append(ln)
    code2 = "\n".join(cleaned).strip()
    pkg_expected, _ = _derive_java_pkg_class(rel_path)
    out_lines: List[str] = []
    saw_pkg = False
    for ln in code2.splitlines():
        if PACKAGE_LINE_RX.match(ln):
            saw_pkg = True
            out_lines.append(f"package {pkg_expected};" if pkg_expected else ln)
        else:
            out_lines.append(ln)
    code3 = "\n".join(out_lines)
    if pkg_expected and not saw_pkg:
        code3 = f"package {pkg_expected};\n{code3}"
    return code3.strip() + "\n"

def _tail(s: str, nbytes: int = 2000) -> str:
    if not s: return ""
    enc = s.encode("utf-8", errors="ignore")
    return enc[-nbytes:].decode("utf-8", errors="ignore")

class JobQueue:
    def __init__(self, hub: StreamHub):
        self.queue: asyncio.Queue[dict] = asyncio.Queue()
        self.hub = hub
        self._task = None
        # Track inflight tasks for cancel
        self._inflight: Dict[str, List[asyncio.Task]] = {}


    def _write_artifact_safely(self, task_id: str, payload: Dict[str, Any]) -> None:
        try:
            write_result(str(task_id), payload)
        except Exception:
            pass

    async def start(self):
        if self._task is None:
            self._task = asyncio.create_task(self._runner())

    async def submit(self, task: dict):
        await self.queue.put(task)

    async def cancel(self, task_id: str):
        tasks = self._inflight.pop(task_id, [])
        for t in tasks:
            if not t.done():
                t.cancel()
        await self.hub.publish(task_id, json.dumps({"status":"canceled"}))
        log.info("task.canceled", {"id": task_id, "canceled_children": len(tasks)})

    async def _write_primary(self, rel_path: str, candidate_dir: Path, generated: str) -> Path:
        rel_path = rel_path.lstrip("/").replace("..","_")
        target = candidate_dir / rel_path
        target.parent.mkdir(parents=True, exist_ok=True)
        target.write_text(generated if generated.strip() else "// (empty)\n", encoding="utf-8")
        return target

    async def _run_candidate_inner(self, job: dict, candidate: Dict[str, Any], task_id: str) -> Dict[str, Any]:
        """Inner function that we can time-limit with wait_for."""
        model_str = _format_model_name(candidate)
        set_candidate(model_str)
        t0 = time.time()

        # isolated dir
        from .fs_sandbox import resolve_safe_path
        from .governance import enforce_fs_write
        safe_model = model_str.replace("/", "_").replace(":", "_").replace("-", "_")
        rel_dir = f".duel/{task_id}/{safe_model}"
        dir_path, ok = resolve_safe_path(rel_dir)
        if not enforce_fs_write(ok, rel_dir):
            raise RuntimeError("Write outside workspace denied")
        dir_path.mkdir(parents=True, exist_ok=True)

        # target path
        expected = (job.get("output_contract") or {}).get("expected_files", []) or []
        rel_primary = expected[0] if expected else "main.txt"

        # prompt + stream
        prompt = _build_prompt(job)
        ctx = int(candidate.get("ctx_size", 8192) or 8192)
        buf_parts: List[str] = []
        try:
            async for chunk in generate_stream(model_str, prompt, num_ctx=ctx, temperature=0.2):
                if "response" in chunk and not chunk.get("done"):
                    buf_parts.append(chunk["response"])
            generated = "".join(buf_parts).strip()
        except OllamaError as e:
            generated = f"// ollama error: {e}\n"
        except asyncio.CancelledError:
            raise
        except Exception as e:
            generated = f"// runtime error: {e}\n"

        # sanitize + write
        to_write = _sanitize_java(generated, rel_primary) if rel_primary.endswith(".java") else generated
        primary_path = await self._write_primary(rel_primary, dir_path, to_write)

        # Build & tests
        compile_pass = False
        test_pass = False
        out_tail = ""
        err_tail = ""
        tool_used = "maven"

        if primary_path.suffix.lower() == ".java":
            c, t, o, e, tool = await build_and_test_java(dir_path)
            compile_pass, test_pass, out_tail, err_tail, tool_used = c, t, o, e, tool
        else:
            compile_pass = bool(to_write.strip())
            test_pass = False

        if compile_pass: compile_pass_total.inc()
        if test_pass:    test_smoke_pass_total.inc()

        latency_ms = int((time.time() - t0) * 1000)

        return {
            "model": model_str,
            "success": bool(test_pass or compile_pass),
            "latency_ms": latency_ms,
            "speed_rank": int(candidate.get("speed_rank", 999)),
            "human_score": 0,
            "compile_pass": bool(compile_pass),
            "test_pass": bool(test_pass),
            "tool": tool_used,
            "logs": {"build_stdout_tail": out_tail, "build_stderr_tail": err_tail},
            "artifact": str(primary_path)
        }

    async def _run_candidate(self, job: dict, candidate: Dict[str, Any], task_id: str) -> Dict[str, Any]:
        try:
            return await asyncio.wait_for(self._run_candidate_inner(job, candidate, task_id), timeout=CANDIDATE_TIMEOUT_SEC)
        except asyncio.TimeoutError:
            log.warning("candidate.timeout", {"task_id": task_id, "model": _format_model_name(candidate), "timeout_sec": CANDIDATE_TIMEOUT_SEC})
            return {
                "model": _format_model_name(candidate),
                "success": False,
                "latency_ms": CANDIDATE_TIMEOUT_SEC*1000,
                "speed_rank": int(candidate.get("speed_rank", 999)),
                "human_score": 0,
                "compile_pass": False,
                "test_pass": False,
                "tool": "timeout",
                "logs": {"build_stdout_tail": "", "build_stderr_tail": f"candidate timed out after {CANDIDATE_TIMEOUT_SEC}s"},
                "artifact": ""
            }
        except asyncio.CancelledError:
            log.info("candidate.canceled", {"task_id": task_id, "model": _format_model_name(candidate)})
            raise

    def _score(self, r: Dict[str, Any], cfg: Dict[str, Any]) -> float:
        base = (cfg["success_weight"] * (1.0 if r["success"] else 0.0))
        test_bonus = float(cfg.get("test_pass_weight", 0.5)) * (1.0 if r.get("test_pass") else 0.0)
        return base + test_bonus - (cfg["latency_penalty_ms"] * float(r["latency_ms"])) + (cfg["human_score_weight"] * float(r.get("human_score", 0) or 0))

    async def _runner(self):
        eng = await get_engine()
        while True:
            job = await self.queue.get()
            id = job["id"]
            set_task_id(str(id))
            language = job["input"]["language"]
            self._inflight[str(id)] = []
            await self.hub.publish(str(id), json.dumps({"status":"running"}))

            feats = extract_features(job)
            fh = feature_hash(feats)

            duel_cfg = (job.get("routing_hints") or {})
            is_duel = bool(duel_cfg.get("duel") or duel_cfg.get("duel_candidates"))

            try:
                if not is_duel:
                    base = available_models(language)
                    async with eng.connect() as conn:
                        ordered = await rank_models(conn, base, fh)
                    m = ordered[0] if ordered else None
                    if not m:
                        raise RuntimeError("no available models")
                    t = asyncio.create_task(self._run_candidate(job, m, str(id)))
                    self._inflight[str(id)].append(t)
                    res = await t
                    reward = 1.0 if res.get("test_pass") else (0.5 if res.get("compile_pass") else 0.0)
                    # --- bandit persistence (auto-injected) ---
                    try:
                        from .bandit_store import record_event as _bandit_record_event
                        _m = (
                            locals().get('model') or locals().get('model_name') or
                            getattr(locals().get('candidate', None), 'model', None) or
                            locals().get('cand_model') or locals().get('name') or 'unknown'
                        )
                        _bandit_record_event(str(_m), float(locals().get('reward')), {'src':'queue'})
                    except Exception:
                        pass

                    async with eng.begin() as conn:
                        await update_task_status(conn, id, "done", model_used=res.get("model"), latency_ms=res.get("latency_ms"))
                        await upsert_stat(conn, res["model"], fh, reward)
                    except Exception:
                        pass
                    except Exception:
                        pass
self._write_artifact_safely(str(id), {
    "status":"done","mode":"single",
    "model":res.get("model"), "latency_ms":res.get("latency_ms"),
    "compile_pass":res.get("compile_pass"), "test_pass":res.get("test_pass"),
    "tool":res.get("tool"), "artifact":res.get("artifact")
})
await self.hub.publish(str(id), json.dumps({
                        "status":"done",
                        "model":res.get("model"), "latency_ms":res.get("latency_ms"),
                        "compile_pass":res.get("compile_pass"), "test_pass":res.get("test_pass"),
                        "tool":res.get("tool"), "artifact":res.get("artifact"), "logs":res.get("logs")
                    }))
                else:
                    cand_names: List[str] = duel_cfg.get("duel_candidates") or []
                    reg_models = available_models(language)
                    name_map = { _format_model_name(m): m for m in reg_models }
                    candidates = [name_map[s] for s in cand_names if s in name_map] if cand_names else reg_models[:2]
                    async with eng.connect() as conn:
                        ordered = await rank_models(conn, candidates, fh)
                    if len(ordered) < 2:
                        # fallback to single
                        m = ordered[0] if ordered else (reg_models[0] if reg_models else None)
                        t = asyncio.create_task(self._run_candidate(job, m, str(id)))
                        self._inflight[str(id)].append(t)
                        res = await t
                        reward = 1.0 if res.get("test_pass") else (0.5 if res.get("compile_pass") else 0.0)
                        async with eng.begin() as conn:
                            await update_task_status(conn, id, "done", model_used=res.get("model"), latency_ms=res.get("latency_ms"))
                            await upsert_stat(conn, res["model"], fh, reward)
                        await self.hub.publish(str(id), json.dumps({"status":"done","model":res.get("model"),"latency_ms":res.get("latency_ms"),
                            "compile_pass":res.get("compile_pass"),"test_pass":res.get("test_pass"),"tool":res.get("tool"),"artifact":res.get("artifact"),"logs":res.get("logs")}))
                        self.queue.task_done(); self._inflight.pop(str(id), None); continue

                    a_meta, b_meta = ordered[0], ordered[1]
                    a_name, b_name = _format_model_name(a_meta), _format_model_name(b_meta)
                    router_route_count.labels(model=a_name, language=language).inc()
                    router_route_count.labels(model=b_name, language=language).inc()
                    await self.hub.publish(str(id), json.dumps({"phase":"duel","candidate":a_name,"status":"running"}))
                    await self.hub.publish(str(id), json.dumps({"phase":"duel","candidate":b_name,"status":"running"}))

                    # run both with a global duel timeout
                    ta = asyncio.create_task(self._run_candidate(job, a_meta, str(id)))
                    tb = asyncio.create_task(self._run_candidate(job, b_meta, str(id)))
                    self._inflight[str(id)].extend([ta, tb])

                    try:
                        a_res, b_res = await asyncio.wait_for(asyncio.gather(ta, tb), timeout=DUEL_TIMEOUT_SEC)
                    except asyncio.TimeoutError:
                        log.warning("duel.timeout", {"task_id": str(id), "timeout_sec": DUEL_TIMEOUT_SEC})
                        # cancel any still-running tasks
                        for t in (ta, tb):
                            if not t.done(): t.cancel()
                        # gather partials
                        done = []
                        for t in (ta, tb):
                            try:
                                done.append(await t)
                            except asyncio.CancelledError:
                                done.append({"model": a_name if t is ta else b_name, "success": False, "latency_ms": DUEL_TIMEOUT_SEC*1000,
                                             "compile_pass": False, "test_pass": False, "tool": "timeout", "logs": {"build_stdout_tail":"","build_stderr_tail":"duel timed out"}, "artifact": ""})
                        a_res, b_res = done

                    await self.hub.publish(str(id), json.dumps({
                        "phase":"duel","candidate":a_res["model"],"status":"done",
                        "metrics":{"success":a_res["success"],"latency_ms":a_res["latency_ms"],"compile_pass":a_res["compile_pass"],"test_pass":a_res["test_pass"]},
                        "tool":a_res["tool"], "artifact":a_res["artifact"], "logs":a_res["logs"]
                    }))
                    await self.hub.publish(str(id), json.dumps({
                        "phase":"duel","candidate":b_res["model"],"status":"done",
                        "metrics":{"success":b_res["success"],"latency_ms":b_res["latency_ms"],"compile_pass":b_res["compile_pass"],"test_pass":b_res["test_pass"]},
                        "tool":b_res["tool"], "artifact":b_res["artifact"], "logs":b_res["logs"]
                    }))

                    cfg = get_duel_config()
                    def score(r):
                        base = (cfg["success_weight"] * (1.0 if r["success"] else 0.0))
                        test_bonus = float(cfg.get("test_pass_weight", 0.5)) * (1.0 if r.get("test_pass") else 0.0)
                        return base + test_bonus - (cfg["latency_penalty_ms"] * float(r["latency_ms"])) + (cfg["human_score_weight"] * float(r.get("human_score",0) or 0))
                    winner, loser = (a_res, b_res) if score(a_res) >= score(b_res) else (b_res, a_res)

                    duel_selection_decisions_total.labels(winner=winner["model"], loser=loser["model"]).inc()
                    duel_rule_decisions_total.labels(rule_version=str(cfg.get("rule_version","v1"))).inc()

                    reward_w = 1.0 if winner.get("test_pass") else (0.5 if winner.get("compile_pass") else 0.0)
                    # bandit: log duel rewards
                    try:
                        bandit_record_event(winner.get("model") or "unknown", float(reward_w), {"src":"queue","task_id": str(id),"mode":"duel","role":"winner","opponent": (loser.get("model") or "unknown")})
                        bandit_record_event(loser.get("model") or "unknown", float(reward_l), {"src":"queue","task_id": str(id),"mode":"duel","role":"loser","opponent": (winner.get("model") or "unknown")})
                    except Exception:
                        pass

                    reward_l = 1.0 if loser.get("test_pass") else (0.5 if loser.get("compile_pass") else 0.0)

                    async with eng.begin() as conn:
                        await update_task_status(conn, id, "done", model_used=winner["model"], latency_ms=min(a_res["latency_ms"], b_res["latency_ms"]))
                        await conn.execute(text("""INSERT INTO rewards (id, task_id, model, success, latency_ms, human_score)
                                                   VALUES (gen_random_uuid(), :tid, :m1, :s1, :l1, NULL)"""),
                                           dict(tid=str(id), m1=winner["model"], s1=bool(winner["success"]), l1=int(winner["latency_ms"])))
                        await conn.execute(text("""INSERT INTO rewards (id, task_id, model, success, latency_ms, human_score)
                                                   VALUES (gen_random_uuid(), :tid, :m2, :s2, :l2, NULL)"""),
                                           dict(tid=str(id), m2=loser["model"], s2=bool(loser["success"]), l2=int(loser["latency_ms"])))
                        await upsert_stat(conn, winner["model"], fh, reward_w)
                        await upsert_stat(conn, loser["model"], fh, reward_l)

                    except Exception:
                        pass
                    except Exception:
                        pass
self._write_artifact_safely(str(id), {
    "status":"done","mode":"duel",
    "winner": winner.get("model"), "loser": loser.get("model"),
    "rule_version": str(cfg.get("rule_version","v1")),
    "winner_metrics": {"success":winner.get("success"), "latency_ms":winner.get("latency_ms"), "compile_pass":winner.get("compile_pass"), "test_pass":winner.get("test_pass"), "tool":winner.get("tool")},
    "loser_metrics": {"success":loser.get("success"), "latency_ms":loser.get("latency_ms"), "compile_pass":loser.get("compile_pass"), "test_pass":loser.get("test_pass"), "tool":loser.get("tool")}
})
await self.hub.publish(str(id), json.dumps({
                        "status":"done",
                        "winner": winner["model"], "loser": loser["model"],
                        "rule_version": str(cfg.get("rule_version","v1")),
                        "winner_metrics":{"success":winner["success"], "latency_ms":winner["latency_ms"],
                                          "compile_pass":winner["compile_pass"], "test_pass":winner["test_pass"], "tool":winner["tool"]},
                        "loser_metrics":{"success":loser["success"], "latency_ms":loser["latency_ms"],
                                         "compile_pass":loser["compile_pass"], "test_pass":loser["test_pass"], "tool":loser["tool"]}
                    }))
            except asyncio.CancelledError:
                # task canceled
                async with eng.begin() as conn:
                    await update_task_status(conn, id, "canceled", model_used=None)
                await self.hub.publish(str(id), json.dumps({"status":"canceled"}))
                log.info("task.cancelled", {"id": str(id)})
            except Exception as e:
                async with eng.begin() as conn:
                    await update_task_status(conn, id, "error", model_used=None)
                await self.hub.publish(str(id), json.dumps({"status":"error","error":str(e)}))
                log.error("task.error", {"id": str(id), "err": str(e)})
            finally:
                self._inflight.pop(str(id), None)
                self.queue.task_done()


# === BANDIT_AUTOWRAP (do not edit) ===
try:
    from .bandit_hook import log_reward as _bandit_log  # type: ignore
    import functools, inspect

    def _bandit_wrap(fn):
        if getattr(fn, "_bandit_wrapped", False):
            return fn
        @functools.wraps(fn)
        def _inner(*args, **kwargs):
            out = fn(*args, **kwargs)
            try:
                model = None
                reward = None
                # If function returns a mapping/dict with fields
                if isinstance(out, dict):
                    reward = out.get("reward", out.get("score"))
                    model = out.get("model") or out.get("name")
                # Fall back to kwargs/locals seen by caller if they pass them through
                if reward is None:
                    # best effort: look into kwargs
                    for k in ("reward","score","final_score","total_reward"):
                        if k in kwargs:
                            reward = kwargs[k]
                            break
                if model is None:
                    for k in ("model","model_name","name","candidate"):
                        if k in kwargs:
                            v = kwargs[k]
                            model = getattr(v, "model", None) if not isinstance(v, (str,type(None))) else v
                            break
                if reward is not None:
                    _bandit_log(model or "unknown", reward, {"src":"queue.wrap","fn":fn.__name__})
                return out
            except Exception:
                return out
        _inner._bandit_wrapped = True
        return _inner

    # Try to wrap likely scoring functions if they exist
    glb = globals()
    for _nm in ("compute_reward","_compute_reward","score_candidate","_score_candidate","finalize_score","_finalize_score"):
        if _nm in glb and callable(glb[_nm]):
            glb[_nm] = _bandit_wrap(glb[_nm])
except Exception:
    pass


# === BANDIT_AUTOWRAP (extended) ===
try:
    from .bandit_hook import log_reward as _bandit_log  # type: ignore
    import functools

    def _bandit_wrap(fn):
        if getattr(fn, "_bandit_wrapped", False):
            return fn
        @functools.wraps(fn)
        def _inner(*args, **kwargs):
            out = fn(*args, **kwargs)
            try:
                model = kwargs.get("model") or kwargs.get("model_name") or kwargs.get("name")
                cand = kwargs.get("candidate")
                if cand is not None and not isinstance(cand, (str,type(None))):
                    model = getattr(cand, "model", model)

                # try common output shapes
                reward = None
                if isinstance(out, dict):
                    for k in ("reward","score","final_score","total_reward","tests_score","compile_score"):
                        if k in out:
                            reward = out[k]; break
                    if not model:
                        for k in ("model","model_name","name"):
                            if k in out:
                                model = out[k]; break

                # fallback to kwargs
                if reward is None:
                    for k in ("reward","score","final_score","total_reward","tests_score","compile_score"):
                        if k in kwargs:
                            reward = kwargs[k]; break

                if reward is not None:
                    _bandit_log(model or "unknown", reward, {"src":"queue.wrap.ext","fn":fn.__name__})
                return out
            except Exception:
                return out
        _inner._bandit_wrapped = True
        return _inner

    glb = globals()
    for _nm in (
        "compute_reward","_compute_reward",
        "score_candidate","_score_candidate",
        "finalize_score","_finalize_score",
        "evaluate_candidate","grade_candidate","calc_score",
    ):
        if _nm in glb and callable(glb[_nm]):
            glb[_nm] = _bandit_wrap(glb[_nm])
except Exception:
    pass


# === ARTIFACT_AUTOWRAP (do not edit) ===
try:
    import functools
    from .artifacts import write_result as _write_artifact  # type: ignore

    def _artifact_wrap(fn):
        if getattr(fn, "_artifact_wrapped", False):
            return fn
        @functools.wraps(fn)
        def _inner(*args, **kwargs):
            out = fn(*args, **kwargs)
            try:
                # Best-effort task_id detection
                tid = (
                    kwargs.get("task_id")
                    or (getattr(args[0], "task_id", None) if args else None)
                    or (out.get("task_id") if isinstance(out, dict) else None)
                    or (out.get("id") if isinstance(out, dict) else None)
                )
                if tid:
                    payload = out if isinstance(out, dict) else {"ok": True}
                    _write_artifact(str(tid), {"ok": True, "task_id": str(tid), "result": payload})
            except Exception:
                pass
            return out
        _inner._artifact_wrapped = True
        return _inner

    glb = globals()
    for _nm in ("run_task","execute_task","process_task","run_duel","duel_runner","handle_task","_run_task"):
        if _nm in glb and callable(glb[_nm]):
            glb[_nm] = _artifact_wrap(glb[_nm])
except Exception:
    pass
